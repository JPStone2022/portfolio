name,slug,description,,,order
AI Development,ai-development,"<p>AI Development: Role: Broad Field/Process.</p><br><p>Use Cases: Encompasses the entire process of creating systems that exhibit intelligent behavior, which includes machine learning but also potentially symbolic reasoning, planning, knowledge representation, robotics, etc. In practice within data science, it often overlaps heavily with ML Development but implies building broader intelligent systems.</p><br><p>Python Libraries: All core ML/DL libraries (Scikit-learn, TensorFlow, PyTorch, Keras), NLP libraries (Hugging Face, spaCy, NLTK), CV libraries (OpenCV, Pillow), potentially libraries for logic programming or planning (less common).</p>",,,0
AI Engineering,ai-engineering,"<p>AI Engineering: Role: System Building & Deployment.</p><br><p>Use Cases: Focuses on the practical implementation, scaling, deployment, and maintenance of AI/ML models and systems in production environments. Overlaps significantly with Machine Learning Engineering and MLOps. Involves building robust data pipelines, creating APIs for models, ensuring reliability and scalability, monitoring performance.</p><br><p>Python Libraries: Core ML/DL libraries (TensorFlow, PyTorch, Scikit-learn), API frameworks (Flask, FastAPI, Django), MLOps tools/libs (MLflow, interacting with Docker/Kubernetes via CLI/APIs), Cloud SDKs (boto3 for AWS, google-cloud-python for GCP, azure-sdk-for-python).</p>",,,1
Apache Spark,apache-spark,<p>Apache Spark: Role: Core Framework (Big Data Processing).</p><br><p>Use Cases: An open-source unified analytics engine for large-scale data processing and machine learning on distributed clusters. Used when datasets are too large to fit into the memory of a single machine. (See also: PySpark).</p>,,,2
Big Data,big-data,"<p>Big Data: Role: Concept & Technology Domain.</p><br><p>Use Cases: Refers to datasets that are too large or complex for traditional data-processing application software. Involves technologies and techniques designed to handle volume, velocity, and variety of data. Data scientists/engineers use tools like Apache Spark, Hadoop ecosystem components, distributed databases, and specific cloud services to process, store, and analyze big data.</p><br><p>Python Libraries: PySpark, Dask, Pandas (often for processing chunks), libraries for specific databases or cloud storage (boto3, etc.).</p>",,,3
Business Intelligence,business-intelligence,"<p>Business Intelligence (BI): Role: Related Field & Application Area.</p><br><p>Use Cases: Focuses on using data, tools, and methodologies to analyze business information and make data-driven decisions. Often involves creating dashboards and reports. Data science techniques can feed into BI systems, and BI tools are often used by data analysts/scientists to present findings.</p><br><p>Python Libraries: Pandas, database connectors (psycopg2, mysql.connector), visualization libraries (Matplotlib, Seaborn, Plotly), libraries to interact with BI tool APIs. (See also: Tableau).</p>",,,4
Chatbot Development,chatbot-development,"<p>Chatbot Development: Role: Application Area (AI/NLP).</p><br><p>Use Cases: Building conversational agents (chatbots, virtual assistants). Leverages NLP techniques for understanding user input (intent recognition, entity extraction) and generating responses. Can range from simple rule-based bots to complex AI-powered ones using large language models (LLMs).</p><br><p>Python Libraries: NLP libraries (NLTK, spaCy, Hugging Face Transformers), specific chatbot frameworks (Rasa, libraries for Dialogflow/Lex APIs), potentially core DL frameworks (TensorFlow, PyTorch) for custom model components.</p>",,,5
Cloud Computing,cloud-computing,"<p>Cloud Computing (AWS, GCP, Azure): Role: Essential Infrastructure & Platform.</p><br><p>Use Cases: Provides scalable resources for storage (S3, GCS, Blob Storage), computation (EC2, Compute Engine, VMs), databases (RDS, Cloud SQL, Cosmos DB), managed ML platforms (SageMaker, Vertex AI, Azure ML), big data services (EMR, Dataproc, HDInsight), and deployment. Essential for handling large datasets, training complex models, and deploying scalable applications.</p><br><p>Python Libraries: Cloud-specific SDKs (boto3 for AWS, google-cloud-python for GCP, azure-sdk-for-python for Azure).</p>",,,6
Command Line,command-line,"<p>Command Line: Role: Fundamental Interface.</p><br><p>Use Cases: Text-based interface for interacting with the operating system. Essential for running scripts, managing files, installing packages, version control (Git), connecting to servers (SSH), and using many development tools. Bash is the most common command line shell on Linux/macOS, while Powershell is common on Windows. (See also: Bash, Powershell).</p><br><p>Python Libraries: subprocess, os, sys, argparse (for building command-line tools).</p>",,,7
Computer Science,computer-science,"<p>Computer Science: Role: Foundational Knowledge.</p><br><p>Use Cases: Provides the theoretical underpinnings for ML/AI/DS. Core concepts like algorithms (searching, sorting, graph algorithms), data structures (arrays, lists, trees, hash maps), complexity analysis (Big O notation), and principles of computation are essential for designing efficient solutions, understanding model trade-offs, and writing optimised code.</p><br><p>Python Libraries: Python's standard library (collections, itertools, math), NumPy.</p>",,,8
Content Creation,content-creation,"<p>Content Creation (AI-driven): Role: Application Area (AI/Generative Models).</p><br><p>Use Cases: Using AI models, particularly generative models, to create new content like text (articles, summaries, code), images (Stable Diffusion, Midjourney), music, or video. Involves using pre-trained models or fine-tuning them for specific styles or tasks.</p><br><p>Python Libraries: Hugging Face Transformers (accessing GPT, T5, etc.), libraries for specific models (e.g., interfaces for Stable Diffusion), image manipulation (Pillow), audio processing (Librosa, torchaudio).</p>",,,9
Cybersecurity,cybersecurity,"<p>Cybersecurity: Role: Application Area & Related Field.</p><br><p>Use Cases: ML and AI are increasingly used in cybersecurity for tasks like intrusion detection, malware analysis, phishing detection, anomaly detection in network traffic, and user behaviour analytics. Data science techniques are used to analyse security logs and identify threats. Conversely, security principles are vital for protecting ML models and data (e.g., adversarial attacks, data privacy).</p><br><p>Python Libraries: Core ML/DL libraries (Scikit-learn, TensorFlow, PyTorch), Pandas/NumPy for log analysis, specific libraries for network analysis (like Scapy, though less common for pure DS/ML roles).</p>",,,10
Data Analysis,data-analysis,"<p>Data Analysis: Role: Core Process/Skill.</p><br><p>Use Cases: The process of inspecting, cleaning, transforming, and modeling data to discover useful information, inform conclusions, and support decision-making. It's a fundamental part of data science, often involving exploratory data analysis (EDA), statistical analysis, and visualisation to understand patterns and trends before or after modelling.</p><br><p>Python Libraries: Pandas (crucial), NumPy, Matplotlib, Seaborn, Plotly, Statsmodels, SciPy.</p>",,,11
Data Engineering,data-engineerling,"<p>Data Engineering: Role: Core Field/Discipline.</p><br><p>Use Cases: Focuses on the practical aspects of building and maintaining systems and infrastructure for data collection, storage, processing, and delivery at scale. Ensures data is reliable, available, and usable for data scientists and analysts. Involves building ETL/ELT pipelines, managing databases and data warehouses, and ensuring data quality.</p><br><p>Python Libraries: Pandas, PySpark, workflow orchestrators (Airflow, Prefect), database connectors (psycopg2, mysql.connector), cloud SDKs (boto3, etc.), potentially data quality tools (Great Expectations).</p>",,,12
Data Inference,data-inference,"<p>Data Inference (Statistical Inference): Role: Core Concept (Statistics/Data Science).</p><br><p>Use Cases: The process of using data analysis to deduce properties of an underlying probability distribution or population based on a sample. It involves hypothesis testing, confidence intervals, and estimating parameters. Essential for drawing statistically valid conclusions from data, evaluating model significance, and understanding uncertainty.</p><br><p>Python Libraries: Statsmodels, SciPy (stats module), Scikit-learn (for model evaluation metrics that relate to inference).</p>",,,13
Data Modeling,data-modeling,"<p>Data Modelling (Database vs. Statistical): Role: Core Process (Multiple Contexts).</p><br><p>Use Cases: Database Context: Designing the structure of a database, defining tables, columns, data types, and relationships (primary/foreign keys) to store data efficiently and consistently. Often done by data engineers or database administrators using SQL DDL. Statistical/ML Context: The process of creating a mathematical or statistical representation (a ""model"") based on data to understand relationships, make predictions, or classify outcomes. This is the core activity of data scientists and ML engineers. Python Libraries (Statistical/ML Context): Scikit-learn, Statsmodels, TensorFlow, PyTorch, Keras, XGBoost, LightGBM.</p>",,,14
Data Science,data-science,"<p>Data Science: Role: Interdisciplinary Field.</p><br><p>Use Cases: A broad field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data. It combines elements of statistics, computer science, and domain expertise. Encompasses data analysis, machine learning, data visualization, and communication.</p><br><p>Python Libraries: The entire ecosystem - NumPy, Pandas, Matplotlib, Seaborn, Scikit-learn, SciPy, Statsmodels, deep learning frameworks, etc.</p>",,,15
Data Warehousing,data-warehousing,"<p>Data Warehousing: Role: Concept & Technology (Data Engineering/BI).</p><br><p>Use Cases: The practice of storing large amounts of structured data from various sources in a central repository (the data warehouse) optimized for querying and analysis (BI). Data engineers design and build warehouses (e.g., using Snowflake, Redshift, BigQuery) and pipelines to load data into them. Data scientists/analysts query these warehouses using SQL.</p><br><p>Python Libraries: Database connectors (psycopg2, etc.), Pandas (for preparing data), potentially libraries interacting with specific warehouse APIs or tools like dbt.</p>",,,16
Database Management,database-management,"<p>Database Management: Role: Related Field/Skill.</p><br><p>Use Cases: Overseeing the operation, maintenance, security, and performance of database systems (relational like PostgreSQL/MySQL or NoSQL like MongoDB). While often a separate role (DBA), data engineers and sometimes data scientists need skills in managing database connections, understanding performance tuning, writing efficient SQL, and ensuring data integrity.</p><br><p>Python Libraries: Database connectors (psycopg2, mysql.connector, pymongo), ORMs (SQLAlchemy, Django ORM).</p>",,,17
Deep Learning,deep-learning,"<p>Deep Learning: Role: Subfield of Machine Learning.</p><br><p>Use Cases: A type of machine learning based on artificial neural networks with multiple layers (deep architectures). Highly effective for complex tasks like image recognition, natural language processing, speech recognition, and generative modeling where traditional ML algorithms might struggle. Requires large datasets and significant computational resources (often GPUs).</p><br><p>Python Libraries: TensorFlow, PyTorch, Keras (as a high-level API).</p>",,,18
Digital Marketing,digital-marketing,"<p>Digital Marketing: Role: Application Area.</p><br><p>Use Cases: Data science and ML are heavily used in digital marketing for customer segmentation, churn prediction, recommendation systems, ad targeting optimization, sentiment analysis of customer feedback, attribution modeling, and forecasting marketing campaign performance.</p><br><p>Python Libraries: Core DS/ML libraries (Pandas, NumPy, Scikit-learn, Statsmodels), potentially NLP libraries, visualization libraries.</p>",,,19
Ethical Hacking,ethical-hacking,"<p>Ethical Hacking: Role: Related Field (Cybersecurity).</p><br><p>Use Cases: While distinct from core ML/DS, there's overlap. Ethical hackers might use data analysis techniques to find patterns in security logs or test the security of ML systems (e.g., probing for adversarial attacks, data poisoning vulnerabilities). Conversely, ML techniques are used to build security tools that ethical hackers might test against. Generally, not a direct part of the ML/DS workflow itself.</p><br><p>Python Libraries: Pandas/NumPy for log analysis, network libraries (Scapy, Requests), potentially ML libraries for analyzing attack patterns.</p>",,,20
Excel Skills,excel-skills,"<p>Excel Skills: Role: Supporting Skill (Data Analysis/Business Context).</p><br><p>Use Cases: Refers to proficiency in using spreadsheet software like Microsoft Excel. Useful for quick data exploration, creating simple visualizations, basic data cleaning, and communicating results to business users familiar with Excel. While valuable, advanced ML/AI/DS work requires moving beyond Excel to programming languages and dedicated libraries.</p><br><p>Python Libraries: Pandas (for reading/writing Excel files: read_excel, to_excel), openpyxl, xlsxwriter.</p>",,,21
Explainable AI,explainable-ai,"<p>Explainable AI (XAI): Role: Core Concept/Subfield (AI/ML Trust & Ethics).</p><br><p>Use Cases: A critical area focused on developing techniques and models that allow humans to understand and interpret the predictions and decisions made by AI/ML systems, especially complex ""black box"" models like deep neural networks. Essential for building trust, debugging models, ensuring fairness, and meeting regulatory requirements in sensitive domains (finance, healthcare).</p><br><p>Python Libraries: SHAP, LIME, InterpretML, libraries integrated into frameworks (Captum for PyTorch, tf-explain for TensorFlow), model-specific interpretation methods.</p>",,,22
Generative AI,generative-ai,"<p>Generative AI: Role: Subfield of AI/Deep Learning.</p><br><p>Use Cases: Focuses on AI models that can create new, original content (text, images, audio, code, etc.) that resembles data they were trained on. Includes models like Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and large language models (LLMs) like GPT. Used in content creation, data augmentation, drug discovery, art generation, etc.</p><br><p>Python Libraries: TensorFlow/Keras, PyTorch, Hugging Face Transformers, specific libraries for models like diffusers (for Stable Diffusion).</p>",,,23
Hadoop Ecosystem,hadoop-ecosystem,"<p>Hadoop Ecosystem: Role: Framework (Big Data Storage & Processing - Less Direct Use Now).</p><br><p>Use Cases: An open-source framework for distributed storage (HDFS - Hadoop Distributed File System) and distributed processing (MapReduce) of very large datasets across clusters of computers. While foundational for big data, direct use of MapReduce is less common now, often replaced by higher-level frameworks like Apache Spark which can run on top of HDFS or other storage systems. Understanding the concepts is still valuable.</p><br><p>Python Libraries: Libraries to interact with HDFS (like hdfs), but more commonly accessed via PySpark.</p>",,,24
Machine Learning,machine-learning,"<p>Machine Learning: Role: Core Field/Discipline.</p><br><p>Use Cases: A subfield of Artificial Intelligence focused on building systems that can learn from and make decisions based on data without being explicitly programmed for every task. Involves algorithms for classification, regression, clustering, dimensionality reduction, etc. It's the engine behind most modern AI applications.</p><br><p>Python Libraries: Scikit-learn (fundamental), TensorFlow, PyTorch, Keras, XGBoost, LightGBM, Statsmodels.</p>",,,25
Machine Learning Pipelines,machine-learning-pipelines,"<p>Machine Learning Pipelines: Role: Core Concept/Process (MLOps/Data Engineering).</p><br><p>Use Cases: The process of automating the end-to-end workflow of a machine learning project, including data extraction, preprocessing, feature engineering, model training, evaluation, deployment, and monitoring. Pipelines ensure reproducibility, scalability, and efficient management of ML systems.</p><br><p>Python Libraries: Scikit-learn (Pipeline object), workflow orchestrators (Airflow, Prefect, Kubeflow Pipelines, MLflow), cloud platform tools (AWS Step Functions, GCP Vertex Pipelines, Azure ML Pipelines).</p>",,,26
Math Skills,math-skills,"<p>Math Skills: Role: Foundational Knowledge.</p><br><p>Use Cases: Refers to the mathematical concepts underpinning ML/AI/DS. Key areas include: Linear Algebra: Essential for understanding data representation (vectors, matrices), dimensionality reduction (PCA), and deep learning operations. Calculus: Needed for understanding model optimization (gradient descent). Probability & Statistics: Crucial for data analysis, model evaluation, understanding uncertainty, and statistical modeling.</p><br><p>Python Libraries: NumPy, SciPy, Statsmodels.</p>",,,27
Model Deployment,model-deployment,"<p>Model Deployment: Role: Core Process (ML Engineering/MLOps).</p><br><p>Use Cases: The process of taking a trained machine learning model and making it available to serve predictions on new data in a production environment. This can involve creating APIs (using Flask/Django/FastAPI), packaging the model (Docker), deploying to cloud platforms (AWS SageMaker, GCP Vertex AI, Azure ML), or embedding on edge devices.</p><br><p>Python Libraries: API frameworks (Flask, FastAPI, Django), model serving libraries (TensorFlow Serving, TorchServe), cloud SDKs (boto3, etc.), serialization libraries (pickle, joblib).</p>",,,29
Natural Language Processing,natural-language-processing,"<p>Natural Language Processing (NLP): Role: Subfield of AI/ML.</p><br><p>Use Cases: Focuses on enabling computers to understand, interpret, and generate human language. Tasks include text classification, sentiment analysis, translation, summarization, question answering, named entity recognition, and chatbot development. Driven heavily by deep learning (Transformers) in recent years.</p><br><p>Python Libraries: Hugging Face Transformers (state-of-the-art), spaCy (production focus), NLTK (traditional/educational), Scikit-learn (for text feature extraction and basic models), TensorFlow/PyTorch/Keras.</p>",,,30
NoSQL Databases,nosql-databases,"<p>NoSQL Databases: Role: Supporting Tool (Database).</p><br><p>Use Cases: A category of databases that do not use the traditional tabular relations of relational databases (SQL). Includes document stores (MongoDB), key-value stores (Redis), wide-column stores (Cassandra), and graph databases (Neo4j). Used in ML/DS for storing unstructured data, large-scale logging, caching, managing graph data (e.g., social networks, knowledge graphs), or when flexible schemas are required. Choice depends on the specific data structure and access patterns needed.</p><br><p>Python Libraries: Specific drivers for each database type (pymongo for MongoDB, redis-py for Redis, cassandra-driver, neo4j).</p>",,,31
Problem Solving,problem-solving,"<p>Problem Solving: Role: Fundamental Skill.</p><br><p>Use Cases: The core ability to understand a problem (business or scientific), break it down, identify potential data-driven or algorithmic solutions, implement them, and evaluate their effectiveness. This underlies all aspects of data science, ML, and AI, from defining project goals to debugging code and interpreting results.</p>",,,32
Programming,programming,"<p>Programming: Role: Fundamental Skill.</p><br><p>Use Cases: Writing code to implement algorithms, process data, build models, create pipelines, and deploy solutions. While Python is dominant, understanding programming concepts (variables, control flow, data structures, functions, classes, testing) is essential regardless of the specific language used. (See also: Python, R Language, etc.).</p>",,,33
Project Management,project-management,"<p>Project Management: Role: Supporting Skill/Process.</p><br><p>Use Cases: Planning, executing, and monitoring data science or ML projects. Involves defining scope and objectives, estimating timelines, managing resources, tracking progress, communicating with stakeholders, and handling risks. Often involves methodologies like Agile (Scrum, Kanban) or CRISP-DM. Important for both individual contributors and team leads.</p><br><p>Python Libraries: Less direct use, but libraries might be used for creating reports or interacting with project management tool APIs (e.g., Jira, Asana via requests).</p>",,,34
Research,research,"<p>Research: Role: Process/Activity.</p><br><p>Use Cases: Investigating new algorithms, techniques, or applications within AI, ML, or data science. Involves reading academic papers, experimenting with novel approaches, designing studies, analyzing results rigorously, and often publishing findings. Can be purely academic or applied research within industry R&D labs. Requires strong theoretical understanding and experimental design skills.</p><br><p>Python Libraries: All core libraries, plus potentially specialized libraries for simulations or specific scientific domains.</p>",,,35
Software Development,software-development,"<p>Software Development: Role: Related Field/Skill Set.</p><br><p>Use Cases: The principles and practices of designing, writing, testing, and maintaining software. Crucial for ML Engineers and AI Engineers building production systems. Includes writing clean/modular code, testing (unit, integration), version control (Git), understanding system design, and often working within frameworks (like Django/Flask). Data scientists also benefit significantly from good software development habits.</p><br><p>Python Libraries: Testing frameworks (unittest, pytest), web frameworks (Django, Flask), ORMs, standard library modules.</p>",,,36
Statistical Analysis,statistical-analysis,"<p>Statistical Analysis: Role: Core Process/Skill.</p><br><p>Use Cases: Applying statistical methods to analyze and interpret data. Involves descriptive statistics (mean, median, variance), inferential statistics (hypothesis testing, confidence intervals), and exploring relationships between variables (correlation, regression). Fundamental to data science and evaluating ML model performance. (See also: Data Inference).</p><br><p>Python Libraries: Pandas, NumPy, SciPy (stats module), Statsmodels.</p>",,,37
Statistical Modeling,statistical-modeling,"<p>Statistical Modeling: Role: Core Process/Skill.</p><br><p>Use Cases: Building mathematical models based on statistical assumptions to understand data relationships and make predictions. Includes linear regression, logistic regression, generalized linear models (GLMs), time series models (ARIMA), etc. Often focused more on interpretability and statistical significance than pure predictive accuracy compared to some ML models.</p><br><p>Python Libraries: Statsmodels (primary), Scikit-learn, SciPy.</p>",,,38
Testing,testing,"<p>Testing: Role: Core Process (Software/ML Engineering).</p><br><p>Use Cases: Verifying that code and models behave as expected. Includes unit tests (testing individual functions/classes), integration tests (testing interactions between components), and sometimes data validation tests or model evaluation checks within ML pipelines. Essential for ensuring reliability, maintainability, and preventing regressions.</p><br><p>Python Libraries: unittest (built-in), pytest (popular alternative), potentially data validation libraries (Pandera, Great Expectations).</p>",,,39
UX Design,ux-design,"<p>UX Design (User Experience Design): Role: Related Field.</p><br><p>Use Cases: Focuses on designing products/interfaces that are easy and enjoyable for users to interact with. Relevant when building dashboards, web applications, or tools that present ML/DS results or allow users to interact with AI models. Good UX ensures that the insights or capabilities provided by the underlying models are actually usable and valuable to the end-user. Not typically a core skill for the ML/DS role itself, but collaboration with UX designers is common.</p>",,,40
Web Design,web-design,"<p>Web Design: Role: Related Field.</p><br><p>Use Cases: Focuses on the visual appearance and layout of websites. Overlaps with UX design but is more concerned with aesthetics (colors, fonts, imagery). Relevant if building front-end interfaces or dashboards. (See also: CSS, HTML, JavaScript).</p>",,,41
Web Development,web-development,"<p>Web Development: Role: Related Field/Skill Set.</p><br><p>Use Cases: Building websites and web applications. Important for ML/AI engineers deploying models as APIs or building interactive web tools. Involves front-end (HTML, CSS, JavaScript) and back-end (Python with Django/Flask, Node.js, etc.) development. (See also: Django, Flask, HTML, CSS, JavaScript).</p>",,,42
Web Scraping,web-scraping,"<p>Web Scraping: Role: Technique (Data Acquisition).</p><br><p>Use Cases: Automatically extracting data from websites when APIs are not available. Used in the data collection phase of many data science projects. (See also: BeautifulSoup, Requests).</p><br><p>Python Libraries: Requests (to fetch page content), BeautifulSoup or lxml (to parse HTML), Scrapy (a full scraping framework).</p>",,,43
